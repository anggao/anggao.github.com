<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>spark - Tag - Ang's Blog</title><link>http://anggao.github.io/tags/spark/</link><description>spark - Tag - Ang's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Wed, 23 Jan 2019 00:00:00 +0000</lastBuildDate><atom:link href="http://anggao.github.io/tags/spark/" rel="self" type="application/rss+xml"/><item><title>Spark Note 01</title><link>http://anggao.github.io/2019-01-23-spark-note-01/</link><pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate><author>Author</author><guid>http://anggao.github.io/2019-01-23-spark-note-01/</guid><description>Driver A Spark driver (aka an applicationâ€™s driver process) is a JVM process that hosts SparkContext for a Spark application. It is the master node in a Spark application. It splits a Spark application into tasks and schedules them to run on executors. A driver is where the task scheduler lives and spawns tasks across workers. A driver coordinates workers and overall execution of tasks. It hosts Web UI for the environment.</description></item></channel></rss>